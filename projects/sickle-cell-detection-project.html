<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sickle Cell Detection Project - Briggs Pugner</title>
    <link rel="stylesheet" href="../styles.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        .project-hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 120px 0 80px;
            text-align: center;
        }
        .project-hero h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
        }
        .project-hero p {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        .project-content {
            max-width: 1000px;
            margin: 0 auto;
            padding: 80px 20px;
        }
        .project-section {
            margin-bottom: 3rem;
        }
        .project-section h2 {
            color: #2563eb;
            font-size: 2rem;
            margin-bottom: 1.5rem;
            border-bottom: 3px solid #2563eb;
            padding-bottom: 0.5rem;
        }
        .project-section h3 {
            color: #1f2937;
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }
        .project-meta {
            background: #f8fafc;
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
        }
        .meta-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
        }
        .meta-item {
            text-align: center;
        }
        .meta-item h4 {
            color: #2563eb;
            margin-bottom: 0.5rem;
        }
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: #000000;
            text-decoration: none;
            font-weight: 500;
            margin-bottom: 2rem;
            transition: color 0.3s ease;
        }
        .back-link:hover {
            color: #333333;
        }
        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin: 1rem 0;
        }
        .tech-tag {
            background: #e0e7ff;
            color: #2563eb;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.9rem;
            font-weight: 500;
        }
        .project-image {
            width: 100%;
            max-width: 600px;
            height: 300px;
            background: #f3f4f6;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 2rem auto;
            color: #6b7280;
            font-size: 1.1rem;
        }
        .impact-box {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            padding: 2rem;
            border-radius: 15px;
            margin: 2rem 0;
        }
    </style>
</head>
<body>
    <div class="project-hero">
        <div class="container">
            <a href="../index.html" class="back-link">
                <i class="fas fa-arrow-left"></i>
                Back to Portfolio
            </a>
            <h1>Sickle Cell Detection and Tracking Dataset and System</h1>
            <p>Complete Pipeline for Automated Sickle Cell Identification and Behavior Analysis</p>
        </div>
    </div>

    <div class="project-content">
        <div class="project-meta">
            <div class="meta-grid">
                <div class="meta-item">
                    <h4>Duration</h4>
                    <p>Fall 2025</p>
                </div>
                <div class="meta-item">
                    <h4>Role</h4>
                    <p>Lead Developer</p>
                </div>
                <div class="meta-item">
                    <h4>Institution</h4>
                    <p>University of Maryland Eastern Shore</p>
                </div>
                <div class="meta-item">
                    <h4>Status</h4>
                    <p>Associated Publication in process</p>
                </div>
            </div>
        </div>

        <div class="project-section">
            <h2>Project Overview</h2>
            <p>This project presents a complete pipeline for automated sickle cell identification and behavior analysis from microscopy images, encompassing dataset curation, annotation, segmentation, feature extraction, detection, and tracking. The system addresses the critical need for automated detection of sickle cell disease, which affects millions worldwide and requires precise morphological analysis for accurate diagnosis.</p>
            
            <div class="project-image">
                <img src="../assets/WebsiteImages/Cell_Full_Image.png" alt="Sickle Cell Detection Results" style="width: 100%; height: 100%; object-fit: cover; border-radius: 10px;">
            </div>
        </div>

        <div class="project-section">
            <h2>Research Objectives</h2>
            <ul>
                <li>Develop accurate automated detection of sickle cell deformation using computer vision</li>
                <li>Create a comprehensive dataset with proper annotation for training and validation</li>
                <li>Implement robust object tracking for temporal analysis of cell behavior</li>
                <li>Achieve high precision and recall in distinguishing sickle vs normal erythrocytes</li>
                <li>Build a complete pipeline from raw microscopy images to analysis results</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Technical Approach</h2>
            <h3>Dataset Preparation and Annotation</h3>
            <p>The dataset comprises 4,462 grayscale microscopy images (3,540 training, 922 validation) annotated according to the YOLO object detection standard, distinguishing "sickle" (class 0) and "normal" (class 1) erythrocytes. Class distribution is balanced (42.4% sickle, 57.6% normal). Image dimensions range from 34×43 to 68×81 pixels.</p>
            
            <h3>Segmentation and Feature Extraction</h3>
            <p>Segmentation employed the Cellpose model cpsam with auto-detected cell diameter, flow threshold 0.4, and probability threshold 0.0. Normalized grayscale images (OpenCV MINMAX) were used. Extracted features include geometric and intensity-based measures: area, perimeter, circularity, aspect ratio, major/minor axes, centroid, and pixel-level intensity statistics.</p>
            
            <h3>Object Detection – YOLO12s Model</h3>
            <p>A YOLO12s detector was trained on an NVIDIA RTX 4060 GPU for 136 epochs (51.2 hours) using the AdamW optimizer and cosine learning-rate annealing (initial 0.001). Mixed precision training improved efficiency. Augmentations included minor rotations, scaling, translations, horizontal flips, HSV jitter, mosaic, mixup, copy-paste, randaugment, and random erasing (p=0.3).</p>
            
            <h3>Cell Tracking and Temporal Analysis</h3>
            <p>A custom Kalman-Hungarian tracker (state vector [x, y, w, h, vx, vy]) maintains object identities across frames. Data association weights centroid distance (70%) and IoU (30%), with maximum centroid distance 50 px and minimum IoU 0.1. Track management parameters: max_age = 15 frames, min_hits = 2.</p>
        </div>

        <div class="project-section">
            <h2>Technologies & Tools</h2>
            <div class="tech-stack">
                <span class="tech-tag">Computer Vision</span>
                <span class="tech-tag">Machine Learning</span>
                <span class="tech-tag">YOLO12s</span>
                <span class="tech-tag">OpenCV</span>
                <span class="tech-tag">Ultralytics</span>
                <span class="tech-tag">PyTorch</span>
                <span class="tech-tag">Cellpose</span>
                <span class="tech-tag">NumPy</span>
                <span class="tech-tag">Pandas</span>
                <span class="tech-tag">Matplotlib</span>
                <span class="tech-tag">SciPy</span>
                <span class="tech-tag">NVIDIA RTX 4060</span>
                <span class="tech-tag">Python</span>
            </div>
        </div>

        <div class="project-section">
            <h2>Key Contributions</h2>
            <ul>
                <li>Developed complete end-to-end pipeline for sickle cell detection and tracking</li>
                <li>Created comprehensive dataset of 4,462 annotated microscopy images with balanced class distribution</li>
                <li>Implemented custom Kalman-Hungarian tracker for robust cell tracking across frames</li>
                <li>Optimized YOLO12s model training with advanced augmentation strategies</li>
                <li>Built custom Python tools for dataset annotation and visualization</li>
                <li>Achieved state-of-the-art performance metrics in sickle cell classification</li>
            </ul>
        </div>


        <div class="project-section">
            <h2>Results & Performance</h2>
            <p>The YOLO12s model achieved exceptional performance metrics:</p>
            <ul>
                <li><strong>mAP@0.5:</strong> 0.9889 (peak 0.9894)</li>
                <li><strong>Precision:</strong> 95.76%</li>
                <li><strong>Recall:</strong> 97.05%</li>
                <li><strong>Training Time:</strong> 51.2 hours over 136 epochs on NVIDIA RTX 4060 GPU</li>
                <li><strong>Dataset Size:</strong> 4,462 images (3,540 training, 922 validation)</li>
                <li><strong>Class Balance:</strong> 42.4% sickle cells, 57.6% normal cells</li>
            </ul>
            <p>The system demonstrates high accuracy in distinguishing sickle versus normal cells and robust object tracking capabilities. The custom tracking algorithm successfully maintains cell identities across frames with optimized data association parameters.</p>
        </div>

        <div class="project-section">
            <h2>Limitations</h2>
            <p>The current system has several limitations that should be addressed:</p>
            <ul>
                <li>Absence of real-time processing capabilities</li>
                <li>Single-center image sources limiting generalizability</li>
                <li>Missing acquisition metadata (microscope model, magnification, staining protocol)</li>
                <li>No DICOM compatibility for clinical integration</li>
                <li>Limited to grayscale microscopy images</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Future Work</h2>
            <p>Future research directions and next steps include:</p>
            <ul>
                <li>Integration of multi-source datasets to improve generalizability</li>
                <li>Implementation of standardized imaging protocols across different institutions</li>
                <li>Development of DICOM compatibility for clinical deployment</li>
                <li>Real-time processing optimization for clinical workflow integration</li>
                <li>Expansion to other blood cell disorders and morphological abnormalities</li>
                <li>Clinical validation studies with medical professionals</li>
                <li>Integration with existing medical imaging systems and electronic health records</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Software and Implementation</h2>
            <p>Core dependencies include OpenCV, Ultralytics (YOLO), PyTorch & Torchvision, NumPy, Pillow, Matplotlib, Pandas, Cellpose, SciPy, and tkinter. Custom modules include the Kalman-Hungarian tracker, GUI for image/video input, and automated visualization pipeline. The system provides comprehensive analysis outputs including per-cell CSV files with morphological, intensity, and classification metrics.</p>
            
            <h3>Hardware Requirements</h3>
            <p>NVIDIA RTX 4060 GPU or equivalent for optimal training performance. The system is designed to run on standard computing hardware with GPU acceleration for deep learning model training and inference.</p>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>Briggs Pugner</h3>
                    <p>Computer Engineering Student at UMES</p>
                </div>
                <div class="footer-section">
                    <h4>Quick Links</h4>
                    <ul>
                        <li><a href="index.html">Portfolio</a></li>
                        <li><a href="index.html#education">Education</a></li>
                        <li><a href="index.html#projects">Projects</a></li>
                        <li><a href="index.html#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2024 Briggs Pugner. All rights reserved.</p>
            </div>
        </div>
    </footer>
</body>
</html>
